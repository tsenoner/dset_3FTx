{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo\n",
    "- [x] get representatives in data\n",
    "- [x] ideam is the same as previous entry\n",
    "- [x] get prot seqs from UniProt (API call)\n",
    "- [x] clean up Pevious FASTA file\n",
    "- [x] combine results with previous FASTA\n",
    "- [x] check for duplicate sequences\n",
    "- [x] extract UniProtID from old CSV and put in new column\n",
    "- [ ] check for duplicates between both dsets\n",
    "- [ ] merge CSV files\n",
    "- [ ] create feature file for protspace3D\n",
    "- [ ] show results in ProtSpace3D (separate those by others)\n",
    "- [ ] Split by this group\n",
    "- [ ] highlight representative\n",
    "- [ ] only look at french data separatelly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] check if possible to get whole sequence of genomic sequences (without UniProt entry)\n",
    "- [ ] retrieve names\n",
    "- [ ] merge activity names\n",
    "- [ ] add french data\n",
    "- [ ] check if cluster\n",
    "- [ ] which dataset clusters best? full, "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NCBI selection by acc_id ([AccID list](https://www.ncbi.nlm.nih.gov/books/NBK25497/table/chapter2.T._entrez_unique_identifiers_ui/?report=objectonly))\n",
    "  - entries comming from WGS, which are they?\n",
    "  - ignore predicted entries, or add but label? -> XM_ XR_ XP_\n",
    "    - maybe in the meantime there exists a match in uniprot?\n",
    "  - Which entries always to keep?\n",
    "  - separation by division? https://www.ncbi.nlm.nih.gov/genbank/samplerecord/#GenBankDivisionA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- how to decide which sequenc to keep?\n",
    "- what could a kind of quality controll be?\n",
    "  - Exclude if protein evidence is at homology or predicted level.\n",
    "  - Include if at protein or transcription level\n",
    "  - Exclude if it comes from EST, DNA, CDNA?\n",
    "  - only take mRNA\n",
    "  - sequences which are experimenally verified to be translated (uniprot: at protein level/transcript level)\n",
    "  - What would be a good decision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original - 954 entries: 623 UniProt IDs; 1 RefSeq IDs; 47 GenBank IDs identified.\n",
      "- 127 full sequences information added by genomic supported alignment\n",
      "Zhang - 1003 entries: 274 UniProt IDs; 85 RefSeq IDs; 596 GenBank IDs identified.\n",
      "Ritu - 119 entries: 8 UniProt IDs, 111 GI numbers identified\n",
      "French - 39 entries: 39 UniProt IDs, identified\n",
      "UniProt - 617 entries: 617 UniProt IDs identified\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BLAST: 100%|██████████| 506/506 [00:00<00:00, 61422.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "831 duplicate sequences were merged.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import dset_3FTx\n",
    "import uniprot_helper\n",
    "import ncbi_helper\n",
    "\n",
    "# importlib.reload(dset_3FTx)\n",
    "# importlib.reload(uniprot_helper)\n",
    "\n",
    "# pd.io.clipboards.to_clipboard(df.to_markdown(), excel=False)\n",
    "\n",
    "# --- PATHS ---\n",
    "base = Path(\"../data\")\n",
    "out_dir = base / \"protspace\"\n",
    "raw = base / \"raw\"\n",
    "helpers = base / \"helpers\"\n",
    "\n",
    "csv_in = raw / \"Ivan_3FTx.csv\"\n",
    "fasta_in = raw / \"3and6_new-2.fasta\"\n",
    "genomic_fasta = raw / \"Translation of 156 sequences.fasta\"\n",
    "zhang_fasta = raw / \"BungarusMulticinctus.fasta\"\n",
    "ritu_csv = raw / \"drysdalia.csv\"\n",
    "french_excel = raw / \"french_data.xls\"\n",
    "uniprot_uids_files = [raw / \"dashev_uniprot.txt\", raw / \"snake_3FTx_sp.txt\"]\n",
    "\n",
    "ncbi_dir = base / \"ncbi_entries\"\n",
    "uniprot_dir = base / \"uniprot_entries\"\n",
    "blast_dir = base / \"blast_out\"\n",
    "# nuc_dir = base / \"gi_number\"\n",
    "taxon_mapper_file = helpers / \"taxon_mapper.csv\"\n",
    "# gi2accid_file = helpers / \"gi2accid.json\"\n",
    "\n",
    "fasta_out = out_dir / \"3FTx.fasta\"\n",
    "csv_out = out_dir / \"3FTx.csv\"\n",
    "\n",
    "# --- MAIN ---\n",
    "uniprot_collector = uniprot_helper.UniProtDataGatherer(uniprot_dir=uniprot_dir)\n",
    "ncbi_collector = ncbi_helper.NcbiDataGatherer(ncbi_dir=ncbi_dir)\n",
    "\n",
    "df_original = dset_3FTx.OriginalDset(\n",
    "    csv_path=csv_in, fasta_path=fasta_in, genomic_fasta_path=genomic_fasta\n",
    ").df\n",
    "df_zhang = dset_3FTx.ZhangDset(fasta_path=zhang_fasta).df\n",
    "df_ritu = dset_3FTx.RituDset(csv_path=ritu_csv).df\n",
    "df_french = dset_3FTx.FrenchDset(excel_path=french_excel).df\n",
    "df_uniprot = dset_3FTx.parse_uniprot_ids_file(uniprot_uids_files=uniprot_uids_files)\n",
    "df = pd.concat(\n",
    "    [df_original, df_french, df_zhang, df_ritu, df_uniprot], ignore_index=True\n",
    ")\n",
    "df = dset_3FTx.map_ids2uniprot(df=df)\n",
    "# 28 of original mature_seq have missing ends or no UniProt entry\n",
    "df = dset_3FTx.get_uniprot_metadata(df=df)\n",
    "df = dset_3FTx.get_ncbi_metadata(df=df)\n",
    "df = df.dropna(subset=\"species\")\n",
    "df = dset_3FTx.add_taxon_id(df=df, taxon_mapper_file=taxon_mapper_file)\n",
    "# TODO: run BLASTp to find UniProt entries\n",
    "#       ignore entries that do already have an acession number\n",
    "df = dset_3FTx.run_blast(\n",
    "    df=df, blast_dir=blast_dir, uniprot_collector=uniprot_collector\n",
    ")\n",
    "df = dset_3FTx.get_uniprot_metadata(df=df)\n",
    "df = dset_3FTx.remove_low_quality_entries(df=df)\n",
    "df = dset_3FTx.manual_curation(df=df)\n",
    "dset_3FTx.save_data(df=df, csv_file=csv_out, fasta_file=fasta_out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract protein activity from name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = {\n",
    "    \"3FTx\": [\n",
    "        \"3FTx\",\n",
    "        \"Three finger toxin\",\n",
    "        \"Three-finger toxin\",\n",
    "        \"Toxin 3FTx\",\n",
    "        \"Toxin\",\n",
    "    ],\n",
    "    \"Adrenergic toxin rho-elapitoxin\": [\n",
    "        \"Adrenergic toxin rho-elapitoxin\",\n",
    "        \"Rho-elapitoxin\",\n",
    "    ],\n",
    "    \"Alpha-bungarotoxin\": [\"Alpha-bungarotoxin\"],\n",
    "    \"Alpha-elapitoxin\": [\"Alpha-elapitoxin\"],\n",
    "    \"Alpha-neurotoxin\": [\"Alpha-neurotoxin\"],\n",
    "    \"Beta-cardiotoxin\": [\"Beta-cardiotoxin\"],\n",
    "    \"Candiduxin\": [\"Candiduxin\"],\n",
    "    \"Cardiotoxin\": [\"Cardiotoxin\"],\n",
    "    \"Clarkitoxin\": [\"Clarkitoxin\"],\n",
    "    \"Cobrotoxin\": [\"Cobrotoxin\"],\n",
    "    \"Cytotoxin\": [\"Cytotoxin\", \"cytotoxin\"],\n",
    "    \"Dendroaspin\": [\"Dendroaspin\"],\n",
    "    \"Dendrotoxin\": [\"Dendrotoxin\"],\n",
    "    \"Erabutoxin\": [\"Erabutoxin\"],\n",
    "    \"Fasciculin\": [\"Fasciculin\"],\n",
    "    \"Frontoxin\": [\"Frontoxin\"],\n",
    "    \"GPIHBP1\": [\"Glycosylphosphatidylinositol\", \"glycosylphosphatidylinositol\"],\n",
    "    \"Hemextin\": [\"Hemextin\"],\n",
    "    \"Irditoxin\": [\"Irditoxin\"],\n",
    "    \"Kappa\": [\"Kappa\"],\n",
    "    \"Long neurotoxin\": [\n",
    "        \"Long neurotoxin\",\n",
    "        \"Long chain neurotoxin\",\n",
    "        \"Long-chain neurotoxin\",\n",
    "    ],\n",
    "    \"Ly6\": [\n",
    "        \"LY6\",\n",
    "        \"Ly6\",\n",
    "        \"Ly-6\",\n",
    "        \"Lymphocyte antigen 6\",\n",
    "        \"LYNX1\",\n",
    "        \"LYPD2\",\n",
    "        \"Prostate stem cell antigen\",\n",
    "        \"lymphocyte antigen 6\",\n",
    "        \"prostate stem cell antigen\",\n",
    "    ],\n",
    "    \"Mambalgin\": [\"Mambalgin\"],\n",
    "    \"Micrurotoxin\": [\"Micrurotoxin\"],\n",
    "    \"Mipartoxin\": [\"Mipartoxin\"],\n",
    "    \"Muscarinic\": [\"Muscarinic\"],\n",
    "    \"Neurotoxin\": [\"Neurotoxin\"],\n",
    "    \"Nicotinic acetylcholine receptor-binding protein\": [\n",
    "        \"Nicotinic acetylcholine receptor-binding protein\"\n",
    "    ],\n",
    "    \"Non-conventional three finger toxin\": [\"Non-conventional three finger toxin\"],\n",
    "    \"Probable weak neurotoxin\": [\n",
    "        \"Probable weak neurotoxin\",\n",
    "        \"probable weak neurotoxin\",\n",
    "    ],\n",
    "    \"Pseudonajatoxin\": [\"Pseudonajatoxin\"],\n",
    "    \"Putative long neurotoxin\": [\n",
    "        \"Putative long chain neurotoxin\",\n",
    "        \"Putative long neurotoxin\",\n",
    "    ],\n",
    "    \"Putative short chain neurotoxin\": [\"Putative short chain neurotoxin\"],\n",
    "    \"Short chain alpha neurotoxin\": [\n",
    "        \"Short chain alpha neurotoxin\",\n",
    "        \"Short-chain neurotoxin\",\n",
    "    ],\n",
    "    \"Short-chain three finger toxin\": [\"Short-chain three finger toxin\"],\n",
    "    \"Short neurotoxin\": [\"Short neurotoxin\", \"short neurotoxin\"],\n",
    "    \"Synergistic-like venom protein\": [\"Synergistic-like venom protein\"],\n",
    "    \"Synergistic-type venom protein\": [\"Synergistic-type venom protein\"],\n",
    "    \"Toxin_TOLIP\": [\"Toxin_TOLIP\"],\n",
    "    \"Three-finger hemachatoxin\": [\"Three-finger hemachatoxin\"],\n",
    "    \"Venom protein\": [\"Venom protein\"],\n",
    "    \"Weak neurotoxin\": [\"Weak neurotoxin\", \"weak neurotoxin\"],\n",
    "    \"Weak toxin\": [\"Weak toxin\"],\n",
    "}\n",
    "\n",
    "# extract protein activity from protein name\n",
    "# new_df[\"new_name\"] = new_df[\"name\"]\n",
    "# for new_name, old_name_lst in new_names.items():\n",
    "#     for old_name in old_name_lst:\n",
    "#         new_df.loc[\n",
    "#             new_df[\"name\"].str.contains(old_name, na=False), \"new_name\"\n",
    "#         ] = new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.copy()\n",
    "for new_name, old_name_lst in new_names.items():\n",
    "    for old_name in old_name_lst:\n",
    "        new_df.loc[new_df[\"name\"].str.startswith(old_name, na=False), \"name\"] = new_name\n",
    "dset_3FTx.save_data(df=new_df, csv_file=csv_out, fasta_file=fasta_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"name\"].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_df(df):\n",
    "    df.index = df.index.fillna(\"NA\")\n",
    "    pd.io.clipboards.to_clipboard(df.to_markdown(), excel=False)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original             802\n",
       "paper_zhang          669\n",
       "genomic              152\n",
       "paper_RituChandna    119\n",
       "Name: data_origin, dtype: int64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"data_origin\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SP    701\n",
      "NA    621\n",
      "TR    267\n",
      "NA    153\n",
      "Name: db, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Entries found in UniProt\n",
    "res = df[\"db\"].value_counts(dropna=False)\n",
    "copy_df(df=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    1303\n",
      "NA      439\n",
      "Name: acc_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# number of UniProt accession IDs with a 100% sequence match\n",
    "res = df[\"acc_id\"].str.split(\",\").str.len().value_counts(dropna=False)\n",
    "copy_df(df=res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dset-3ftx-zbvyu_fa-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f81b69f198023846c7ea0ce443045fb0d01be6197a356388c4bf1ce48e9cf6b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
