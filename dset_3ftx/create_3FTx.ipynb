{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo\n",
    "- [x] get representatives in data\n",
    "- [x] ideam is the same as previous entry\n",
    "- [x] get prot seqs from UniProt (API call)\n",
    "- [x] clean up Pevious FASTA file\n",
    "- [x] combine results with previous FASTA\n",
    "- [x] check for duplicate sequences\n",
    "- [x] extract UniProtID from old CSV and put in new column\n",
    "- [ ] check for duplicates between both dsets\n",
    "- [ ] merge CSV files\n",
    "- [ ] create feature file for protspace3D\n",
    "- [ ] show results in ProtSpace3D (separate those by others)\n",
    "- [ ] Split by this group\n",
    "- [ ] highlight representative\n",
    "- [ ] only look at french data separatelly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] check if possible to get whole sequence of genomic sequences (without UniProt entry)\n",
    "- [ ] retrieve names\n",
    "- [ ] merge activity names\n",
    "- [ ] add french data\n",
    "- [ ] check if cluster\n",
    "- [ ] which dataset clusters best? full, "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NCBI selection by acc_id ([AccID list](https://www.ncbi.nlm.nih.gov/books/NBK25497/table/chapter2.T._entrez_unique_identifiers_ui/?report=objectonly))\n",
    "  - entries comming from WGS, which are they?\n",
    "  - ignore predicted entries, or add but label? -> XM_ XR_ XP_\n",
    "    - maybe in the meantime there exists a match in uniprot?\n",
    "  - Which entries always to keep?\n",
    "  - separation by division? https://www.ncbi.nlm.nih.gov/genbank/samplerecord/#GenBankDivisionA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- how to decide which sequenc to keep?\n",
    "- what could a kind of quality controll be?\n",
    "  - Exclude if protein evidence is at homology or predicted level.\n",
    "  - Include if at protein or transcription level\n",
    "  - Exclude if it comes from EST, DNA, CDNA?\n",
    "  - only take mRNA\n",
    "  - sequences which are experimenally verified to be translated (uniprot: at protein level/transcript level)\n",
    "  - What would be a good decision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original - 954 entries: 623 UniProt IDs; 1 RefSeq IDs; 47 GenBank IDs identified.\n",
      "- 127 full sequences information added by genomic supported alignment\n",
      "Zhang - 970 entries: 274 UniProt IDs; 56 RefSeq IDs; 595 GenBank IDs identified.\n",
      "Ritu - 119 entries: 8 UniProt IDs, 111 GI numbers identified\n",
      "French - 39 entries: 39 UniProt IDs, identified\n",
      "UniProt - 617 entries: 617 UniProt IDs identified\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BLAST: 100%|██████████| 745/745 [00:00<00:00, 61929.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231 low quality sequences removed\n",
      "958 duplicate sequences were merged.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import dset_3FTx\n",
    "import uniprot_helper\n",
    "import ncbi_helper\n",
    "\n",
    "# pd.io.clipboards.to_clipboard(df.to_markdown(), excel=False)\n",
    "\n",
    "# --- PATHS ---\n",
    "base = Path(\"../data\")\n",
    "out_dir = base / \"protspace\"\n",
    "raw = base / \"raw\"\n",
    "helpers = base / \"helpers\"\n",
    "\n",
    "csv_in = raw / \"Ivan_3FTx.csv\"\n",
    "fasta_in = raw / \"3and6_new-2.fasta\"\n",
    "genomic_fasta = raw / \"Translation of 156 sequences.fasta\"\n",
    "zhang_fasta = raw / \"BungarusMulticinctus.fasta\"\n",
    "zhang_sp6_fasta = raw / \"zhang_sp6_mature_seq.fasta\"\n",
    "zhang_annotation = raw / \"zhang_annotation.xlsx\"\n",
    "ritu_csv = raw / \"drysdalia.csv\"\n",
    "french_excel = raw / \"french_data.xls\"\n",
    "uniprot_uids_files = [raw / \"dashevsky_uniprot.txt\", raw / \"snake_3FTx_sp.txt\"]\n",
    "\n",
    "ncbi_dir = base / \"ncbi_entries\"\n",
    "uniprot_dir = base / \"uniprot_entries\"\n",
    "blast_dir = base / \"blast_out\"\n",
    "taxon_mapper_file = helpers / \"taxon_mapper.csv\"\n",
    "name_activity_file = helpers / \"name_activity.json\"\n",
    "\n",
    "fasta_out = out_dir / \"3FTx.fasta\"\n",
    "csv_out = out_dir / \"3FTx.csv\"\n",
    "\n",
    "# --- MAIN ---\n",
    "uniprot_collector = uniprot_helper.UniProtDataGatherer(uniprot_dir=uniprot_dir)\n",
    "ncbi_collector = ncbi_helper.NcbiDataGatherer(ncbi_dir=ncbi_dir)\n",
    "\n",
    "df_original = dset_3FTx.OriginalDset(\n",
    "    csv_path=csv_in, fasta_path=fasta_in, genomic_fasta_path=genomic_fasta\n",
    ").df\n",
    "df_zhang = dset_3FTx.ZhangDset(\n",
    "    fasta_path=zhang_fasta,\n",
    "    mature_fasta_path=zhang_sp6_fasta,\n",
    "    annotation_excel_path=zhang_annotation,\n",
    ").df\n",
    "df_ritu = dset_3FTx.RituDset(csv_path=ritu_csv).df\n",
    "df_french = dset_3FTx.FrenchDset(excel_path=french_excel).df\n",
    "df_uniprot = dset_3FTx.parse_uniprot_ids_file(uniprot_uids_files=uniprot_uids_files)\n",
    "df = pd.concat(\n",
    "    [df_original, df_french, df_uniprot, df_ritu, df_zhang], ignore_index=True\n",
    ")\n",
    "df = dset_3FTx.map_ids2uniprot(df=df)\n",
    "# 28 of original mature_seq have missing ends or no UniProt entry\n",
    "df = dset_3FTx.get_uniprot_metadata(df=df)\n",
    "df = dset_3FTx.get_ncbi_metadata(df=df)\n",
    "df = df.dropna(subset=\"species\")\n",
    "df = dset_3FTx.add_taxon_id(df=df, taxon_mapper_file=taxon_mapper_file)\n",
    "# run BLASTp to find UniProt entries (ignore entries that already have a uniprot_id)\n",
    "df = dset_3FTx.run_blast(\n",
    "    df=df, blast_dir=blast_dir, uniprot_collector=uniprot_collector\n",
    ")\n",
    "df = dset_3FTx.get_uniprot_metadata(df=df)\n",
    "df = dset_3FTx.remove_low_quality_entries(df=df)\n",
    "df = dset_3FTx.manual_curation(df=df)\n",
    "df = dset_3FTx.infer_activit_from_name(df=df, name_activity_file=name_activity_file)\n",
    "dset_3FTx.save_data(df=df, csv_file=csv_out, fasta_file=fasta_out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original             954\n",
       "paper_zhang          471\n",
       "paper_ritu            38\n",
       "snake_3FTx_sp         31\n",
       "dashevsky_uniprot     16\n",
       "Name: data_origin, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"data_origin\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_df(df):\n",
    "    df.index = df.index.fillna(\"NA\")\n",
    "    pd.io.clipboards.to_clipboard(df.to_markdown(), excel=False)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original             802\n",
       "paper_zhang          669\n",
       "genomic              152\n",
       "paper_RituChandna    119\n",
       "Name: data_origin, dtype: int64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"data_origin\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"mature_seq\"].isna() & df[\"full_seq\"].notna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paper_zhang    54\n",
       "Name: data_origin, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"mature_seq\"].isna() & df[\"full_seq\"].notna()][\"data_origin\"].value_counts(\n",
    "    dropna=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253 791\n"
     ]
    }
   ],
   "source": [
    "print(df[\"mature_seq\"].notna().sum(), df[\"full_seq\"].notna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SP    701\n",
      "NA    621\n",
      "TR    267\n",
      "NA    153\n",
      "Name: db, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Entries found in UniProt\n",
    "res = df[\"db\"].value_counts(dropna=False)\n",
    "copy_df(df=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    1303\n",
      "NA      439\n",
      "Name: acc_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# number of UniProt accession IDs with a 100% sequence match\n",
    "res = df[\"acc_id\"].str.split(\",\").str.len().value_counts(dropna=False)\n",
    "copy_df(df=res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dset-3ftx-zbvyu_fa-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f81b69f198023846c7ea0ce443045fb0d01be6197a356388c4bf1ce48e9cf6b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
