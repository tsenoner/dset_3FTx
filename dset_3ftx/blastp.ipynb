{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfaidx import Fasta\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import uniprot_helper\n",
    "import ncbi_helper\n",
    "\n",
    "base = Path(\"../data\")\n",
    "raw = base / \"raw\"\n",
    "file = raw / \"BungarusMulticinctus.fasta\"\n",
    "ncbi_dir = base / \"ncbi_entries\"\n",
    "uniprot_dir = base / \"uniprot_entries\"\n",
    "\n",
    "taxon_mapper = {\n",
    "    \"Pbiv\": \"Python bivittatus\",\n",
    "    \"Cvir\": \"Crotalus viridis\",\n",
    "    \"Dacu\": \"Deinagkistrodon acutus\",\n",
    "    \"Nnaj\": \"Naja naja\",\n",
    "    \"Hcur\": \"Hydrophis curtus\",\n",
    "    \"Bmul\": \"Bungarus multicinctus\",\n",
    "    \"Pgut\": \"Pantherophis guttatus\",\n",
    "    \"Tele\": \"Thamnophis elegans\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pbiv_NW_006541926_1_gene_1_mRNA_1\n",
      "MKAWLLALVVVALVGTDPVDALECCTGFLCLSSKECAEGEEFCISVCKTKGLIVNEVIRRCAKTCTYPEPVNIKCCSTDYCNLFITPHCPLLSLLT\n"
     ]
    }
   ],
   "source": [
    "fasta = Fasta(file)\n",
    "a = []\n",
    "\n",
    "\n",
    "entries = []\n",
    "uniprot_collector = uniprot_helper.UniProtDataGatherer(uniprot_dir=uniprot_dir)\n",
    "ncbi_collector = ncbi_helper.NcbiDataGatherer(ncbi_dir=ncbi_dir)\n",
    "for header, seq in fasta.items():\n",
    "    ncbi_id = None\n",
    "    seq = str(seq).replace(\"-\", \"\")\n",
    "    species_id = header.split(\"_\")[0]\n",
    "    if species_id not in taxon_mapper:\n",
    "        if species_id in [\"L\", \"S\", \"N\", \"NX\"]:\n",
    "            # uniprot entries\n",
    "            m = re.search(r\"([A-Z0-9]+)_([A-Z0-9]+_[A-Z]+)$\", header).groups()\n",
    "            acc_id, entry = m\n",
    "            data = uniprot_collector.get_entry(acc_id=acc_id)\n",
    "            species, taxon_id = uniprot_collector.parse_taxon(rec=data)\n",
    "            full_seq, mature_peptide = uniprot_collector.parse_seq(rec=data)\n",
    "            entry = dict(acc_id=acc_id, species=species, taxon_id=taxon_id)\n",
    "            if (seq == mature_peptide) or (seq == full_seq):\n",
    "                entry.update(dict(seq=mature_peptide, full_seq=full_seq))\n",
    "            else:\n",
    "                raise Exception(f\"Sequence doesn't match its UniProt entry: {acc_id}\")\n",
    "        elif species_id in [\"ly6e\", \"lypd2\", \"lynx1\", \"slurp2\"]:\n",
    "            m = re.match(r\"^[a-z\\d]+_[\\w\\-]+?[_-]([MNPX]{2}_\\d+).*$\", header)\n",
    "            if m is None:\n",
    "                # impossible to extract/get information (4 entries)\n",
    "                continue\n",
    "            ncbi_id = m[1]\n",
    "        else:\n",
    "            m = re.search(r\"^([A-Z]{,5})_(\\w+)(?:\\.\\w+)?$\", header)\n",
    "            code, ncbi_id = m.groups()\n",
    "    else:\n",
    "        # entries that come from genomic DNA\n",
    "        # TODO: BLASTp\n",
    "        species = taxon_mapper[species_id]\n",
    "        entry = dict(species=species, seq=seq)\n",
    "        # print(header)\n",
    "        # print(seq)\n",
    "        # break\n",
    "        continue\n",
    "    if ncbi_id is not None:\n",
    "        ncbi_rec = ncbi_collector.get_record(ncbi_id)\n",
    "        # TODO: check if record is a UniProt/SwissProt entry: sp crossref\n",
    "        species, taxon_id = ncbi_collector.parse_taxon(rec=ncbi_rec)\n",
    "        if species == \"Sistrurus catenatus edwardsi\":\n",
    "            species = \"Sistrurus catenatus edwardsii\"\n",
    "        # TODO: checker: Counter({'TSA': 356, 'VRT': 203, 'HTC': 16, 'EST': 30})\n",
    "        div = ncbi_rec[\"GBSeq_division\"]\n",
    "        full_seq = ncbi_collector.parse_seq(rec=ncbi_rec)\n",
    "        if full_seq is None:\n",
    "            continue\n",
    "        # TODO: create entry\n",
    "        entry = dict(species=species, taxon_id=taxon_id, full_seq=full_seq)\n",
    "    entry.update(dict(fasta_id=header, data_origin=\"paper_zhang\"))\n",
    "    entries.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dset_3FTx\n",
    "\n",
    "base = Path(\"../data\")\n",
    "helpers = base / \"helpers\"\n",
    "blast_dir = base / \"blast_out\"\n",
    "taxon_mapper_file = helpers / \"taxon_mapper.json\"\n",
    "\n",
    "df = pd.DataFrame(entries)\n",
    "df = dset_3FTx.add_taxon_id(df=df, taxon_mapper_file=taxon_mapper_file)\n",
    "df = dset_3FTx.run_blast(df, blast_dir=blast_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(entries)[\"acc_id\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(705, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    577\n",
       "Name: acc_id, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"acc_id\"].dropna().str.split(\",\").str.len().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN     285\n",
       "TR      236\n",
       "None    113\n",
       "SP       71\n",
       "Name: db, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"db\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched: 275 / 275\n",
      "Fetched: 53 / 53\n"
     ]
    }
   ],
   "source": [
    "import idmapping\n",
    "\n",
    "missing = list(mapper.keys())\n",
    "for from_db in [\"EMBL-GenBank-DDBJ\", \"EMBL-GenBank-DDBJ_CDS\"]:\n",
    "    # get mapped IDs\n",
    "    job_id = idmapping.submit_id_mapping(\n",
    "        from_db=from_db, to_db=\"UniProtKB\", ids=missing\n",
    "    )\n",
    "    if idmapping.check_id_mapping_results_ready(job_id):\n",
    "        link = idmapping.get_id_mapping_results_link(job_id)\n",
    "        results = idmapping.get_id_mapping_results_search(link)\n",
    "    # add mapped ID\n",
    "#     seqdb2gi = {gb: gi for gi, gb in gi2seqdb.items()}\n",
    "#     for result in results[\"results\"]:\n",
    "#         gi_nr = seqdb2gi[result[\"from\"]]\n",
    "#         acc_id = result[\"to\"][\"primaryAccession\"]\n",
    "#         df_ritu.loc[df_ritu[\"gi_number\"] == gi_nr, [\"acc_id\"]] = acc_id\n",
    "#     # search missing ones in next DB\n",
    "#     missing = results[\"failedIds\"].copy()\n",
    "# print(\n",
    "#     \"No UniProt AccID found for\"\n",
    "#     f\" {len(results['failedIds'])} sequence(s)\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dset-3ftx-zbvyu_fa-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f81b69f198023846c7ea0ce443045fb0d01be6197a356388c4bf1ce48e9cf6b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
